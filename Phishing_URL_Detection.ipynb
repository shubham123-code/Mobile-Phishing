{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f41546c8",
      "metadata": {
        "id": "f41546c8"
      },
      "source": [
        "# Phishing URL Detection\n",
        "\n",
        "The Internet has become an indispensable part of\n",
        "our life, However, It also has provided opportunities to anonymously perform malicious activities like Phishing. Phishers try to deceive their victims by social engineering or creating mockup websites to steal information such as account ID, username, password from individuals and organizations. Although many methods have been proposed to detect phishing websites, Phishers have evolved their methods to escape from these detection methods. One of the most successful methods for detecting these malicious activities is Machine Learning. This is because most Phishing attacks have some common characteristics which can be identified by machine learning methods."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86acf7a9",
      "metadata": {
        "id": "86acf7a9"
      },
      "source": [
        "The steps demonstrated in this notebook are:\n",
        "\n",
        "1. Loading the data\n",
        "2. Familiarizing with data & EDA\n",
        "3. Visualizing the data\n",
        "4. Splitting the data\n",
        "5. Training the data\n",
        "6. Comparision of Model\n",
        "7. Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ca7313",
      "metadata": {
        "id": "51ca7313"
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "woVXty8FVDo4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woVXty8FVDo4",
        "outputId": "e1e018bb-cd8d-4cf3-a460-7b8bcd7fad40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Apr 15 22:26:10 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# prompt: gpu use code\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eYCEM2rhMe17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "eYCEM2rhMe17",
        "outputId": "3bf05947-6835-425d-8451-bd0f09f5cdcf"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-148b7e1789d7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7db94f12",
      "metadata": {
        "id": "7db94f12"
      },
      "source": [
        "## 1. Loading Data:\n",
        "\n",
        "The dataset created by our team for about 2000 urls containing equal amounts of phishing websites and non phishing websites\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec491f22",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ec491f22"
      },
      "outputs": [],
      "source": [
        "#Loading data into dataframe\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/btp/binary_features_train_unbalanced.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BIiTI7hVNGc6",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BIiTI7hVNGc6"
      },
      "outputs": [],
      "source": [
        "# prompt: remove unnamed columns from data\n",
        "\n",
        "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "data.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
        "data.drop('url', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SBuj1Ddvt5w7",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SBuj1Ddvt5w7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O2-lBlXeNPJf",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O2-lBlXeNPJf"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bD_wI-vANZKX",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bD_wI-vANZKX"
      },
      "outputs": [],
      "source": [
        "# prompt: in data df in column status replace benign with 1 and phishing with 0\n",
        "\n",
        "data['status'].replace('benign', 0, inplace=True)\n",
        "data['status'].replace('phishing', 1, inplace=True)\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eCXnecVm5peF",
      "metadata": {
        "id": "eCXnecVm5peF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0413b490",
      "metadata": {
        "id": "0413b490"
      },
      "source": [
        "## 2. Familiarizing with Data & EDA:\n",
        "In this step, few dataframe methods are used to look into the data and its features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ccdddc5",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9ccdddc5"
      },
      "outputs": [],
      "source": [
        "#Shape of dataframe\n",
        "\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e2ca3b",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c1e2ca3b"
      },
      "outputs": [],
      "source": [
        "#Listing the features of the dataset\n",
        "\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec005bb",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ec005bb"
      },
      "outputs": [],
      "source": [
        "#Information about the dataset\n",
        "\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18c1e021",
      "metadata": {
        "id": "18c1e021"
      },
      "outputs": [],
      "source": [
        "# nunique value in columns\n",
        "\n",
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LTi8o5flnjuy",
      "metadata": {
        "id": "LTi8o5flnjuy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c7df9b",
      "metadata": {
        "id": "d4c7df9b"
      },
      "outputs": [],
      "source": [
        "#description of dataset\n",
        "\n",
        "data.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48657bd4",
      "metadata": {
        "id": "48657bd4"
      },
      "source": [
        "data_set.append(9 OBSERVATIONS:\n",
        "1. There are 11054 instances and 31 fearures in dataset.\n",
        "2. Out of which 30 are independent features where as 1 is dependent feature.\n",
        "3. Each feature is in int datatype, so there is no need to use LabelEncoder.\n",
        "4. There is no outlier present in dataset.\n",
        "5. There is no missing value in dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1cda572",
      "metadata": {
        "id": "d1cda572"
      },
      "source": [
        "## 3. Visualizing the data:\n",
        "Few plots and graphs are displayed to find how the data is distributed and the how features are related to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60aef83b",
      "metadata": {
        "id": "60aef83b"
      },
      "outputs": [],
      "source": [
        "#Correlation heatmap\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(data.corr(), annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1999dba3",
      "metadata": {
        "id": "1999dba3"
      },
      "outputs": [],
      "source": [
        "# Phishing Count in pie chart\n",
        "\n",
        "data['status'].value_counts().plot(kind='pie',autopct='%1.2f%%')\n",
        "plt.title(\"Phishing Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eee8c08",
      "metadata": {
        "id": "3eee8c08"
      },
      "source": [
        "## 4. Splitting the Data:\n",
        "The data is split into train & test sets, 80-20 split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d90a24",
      "metadata": {
        "id": "f3d90a24"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into dependant and independant fetature\n",
        "\n",
        "X = data.drop([\"status\"],axis =1)\n",
        "y = data[\"status\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de941d7",
      "metadata": {
        "id": "9de941d7"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into train and test sets: 80-20 split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E2gKqaSkPfAp",
      "metadata": {
        "id": "E2gKqaSkPfAp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1ae9dc",
      "metadata": {
        "id": "1f1ae9dc"
      },
      "source": [
        "## 5. Model Building & Training:\n",
        "   Supervised machine learning is one of the most commonly used and successful types of machine learning. Supervised learning is used whenever we want to predict a certain outcome/label from a given set of features, and we have examples of features-label pairs. We build a machine learning model from these features-label pairs, which comprise our training set. Our goal is to make accurate predictions for new, never-before-seen data.\n",
        "\n",
        "   There are two major types of supervised machine learning problems, called classification and regression. Our data set comes under regression problem, as the prediction of suicide rate is a continuous number, or a floating-point number in programming terms. The supervised machine learning models (regression) considered to train the dataset in this notebook are:\n",
        "\n",
        "1. Logistic Regression\n",
        "2. k-Nearest Neighbors\n",
        "3. Support Vector Clasifier\n",
        "4. Naive Bayes\n",
        "5. Decision Tree\n",
        "6. Random Forest\n",
        "7. Gradient Boosting\n",
        "8. Catboost\n",
        "9. Xgboost\n",
        "10. Multilayer Perceptrons\n",
        "\n",
        "              \n",
        "  The metrics considered to evaluate the model performance are Accuracy & F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ac1416",
      "metadata": {
        "id": "55ac1416"
      },
      "outputs": [],
      "source": [
        "# Creating holders to store the model performance results\n",
        "ML_Model = []\n",
        "avg_accuracy = []\n",
        "max_accuracy = []\n",
        "avg_f1_score = []\n",
        "max_f1_score = []\n",
        "avg_tpr = []\n",
        "max_tpr = []\n",
        "avg_precision = []\n",
        "max_precision = []\n",
        "avg_tnr = []\n",
        "max_tnr = []\n",
        "avg_fpr = []\n",
        "max_fpr = []\n",
        "#function to call for storing the results\n",
        "def storeResults(model, a,b,c,d,e,f,g,h,i,j,k,l):\n",
        "  ML_Model.append(model)\n",
        "  avg_accuracy.append(round(a, 3))\n",
        "  max_accuracy.append(round(b, 3))\n",
        "  avg_f1_score.append(round(c, 3))\n",
        "  max_f1_score.append(round(d, 3))\n",
        "  avg_precision.append(round(e, 3))\n",
        "  max_precision.append(round(f, 3))\n",
        "  avg_tpr.append(round(g, 3))\n",
        "  max_tpr.append(round(h, 3))\n",
        "  avg_tnr.append(round(i, 3))\n",
        "  max_tnr.append(round(j, 3))\n",
        "  avg_fpr.append(round(k, 3))\n",
        "  max_fpr.append(round(l, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hgVe2PTdsR6O",
      "metadata": {
        "id": "hgVe2PTdsR6O"
      },
      "outputs": [],
      "source": [
        "def calculate_max(lst):\n",
        "    \"\"\"\n",
        "    Find the maximum value in a list.\n",
        "\n",
        "    Parameters:\n",
        "    lst (list): A list of numerical values.\n",
        "\n",
        "    Returns:\n",
        "    float or int: The maximum value in the list.\n",
        "    \"\"\"\n",
        "    if len(lst) == 0:\n",
        "        raise ValueError(\"List is empty\")\n",
        "    max_value = lst[0]\n",
        "    for val in lst:\n",
        "        if val > max_value:\n",
        "            max_value = val\n",
        "    return max_value\n",
        "\n",
        "def calculate_average(lst):\n",
        "    \"\"\"\n",
        "    Calculate the average of all values in a list.\n",
        "\n",
        "    Parameters:\n",
        "    lst (list): A list of numerical values.\n",
        "\n",
        "    Returns:\n",
        "    float: The average of all values in the list.\n",
        "    \"\"\"\n",
        "    total_sum = sum(lst)\n",
        "    average = total_sum / len(lst)\n",
        "    return average\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8724a53",
      "metadata": {
        "id": "a8724a53"
      },
      "source": [
        "## 5.1. Logistic Regression\n",
        "\n",
        "Logistic regression predicts the output of a categorical dependent variable. Therefore the outcome must be a categorical or discrete value. Logistic Regression is much similar to the Linear Regression except that how they are used. Linear Regression is used for solving Regression problems, whereas Logistic regression is used for solving the classification problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa0632f",
      "metadata": {
        "id": "1aa0632f"
      },
      "outputs": [],
      "source": [
        "# Linear regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.pipeline import Pipeline\n",
        "\n",
        "# instantiate the model\n",
        "log = LogisticRegression()\n",
        "\n",
        "# fit the model\n",
        "log.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66af98cc",
      "metadata": {
        "id": "66af98cc"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "\n",
        "y_train_log = log.predict(X_train)\n",
        "y_test_log = log.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4f1e81",
      "metadata": {
        "id": "bd4f1e81"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_log = metrics.accuracy_score(y_train,y_train_log)\n",
        "acc_test_log = metrics.accuracy_score(y_test,y_test_log)\n",
        "print(\"Logistic Regression : Accuracy on training Data: {:.3f}\".format(acc_train_log))\n",
        "print(\"Logistic Regression : Accuracy on test Data: {:.3f}\".format(acc_test_log))\n",
        "print()\n",
        "\n",
        "f1_score_train_log = metrics.f1_score(y_train,y_train_log)\n",
        "f1_score_test_log = metrics.f1_score(y_test,y_test_log)\n",
        "print(\"Logistic Regression : f1_score on training Data: {:.3f}\".format(f1_score_train_log))\n",
        "print(\"Logistic Regression : f1_score on test Data: {:.3f}\".format(f1_score_test_log))\n",
        "print()\n",
        "\n",
        "precision_score_train_log = metrics.precision_score(y_train,y_train_log)\n",
        "precision_score_test_log = metrics.precision_score(y_test,y_test_log)\n",
        "print(\"Logistic Regression : precision on training Data: {:.3f}\".format(precision_score_train_log))\n",
        "print(\"Logistic Regression : precision on test Data: {:.3f}\".format(precision_score_test_log))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_log).ravel()\n",
        "tpr_score_train_log  =  tp / (tp + fn)\n",
        "tnr_score_train_log  =  tn / (tn + fp)\n",
        "fpr_score_train_log  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_log).ravel()\n",
        "tpr_score_test_log  =  tp / (tp + fn)\n",
        "tnr_score_test_log  =  tn / (tn + fp)\n",
        "fpr_score_test_log  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_log))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_log))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_log))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_log))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_log))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_log))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dGD8WWVr3JD2",
      "metadata": {
        "id": "dGD8WWVr3JD2"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    log = LogisticRegression()\n",
        "\n",
        "    # fit the model\n",
        "    log.fit(X_train,y_train)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_log_fold = log.predict(X_test_fold)\n",
        "    y_train_log_fold =  log.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_log_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_log_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_log_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_log_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_log_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_log_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_log_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_log_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GsVykon430Kb",
      "metadata": {
        "id": "GsVykon430Kb"
      },
      "outputs": [],
      "source": [
        "print(\"log\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314ae927",
      "metadata": {
        "id": "314ae927"
      },
      "outputs": [],
      "source": [
        "#computing the classification report of the model\n",
        "\n",
        "print(metrics.classification_report(y_test, y_test_log))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e557df04",
      "metadata": {
        "id": "e557df04"
      },
      "outputs": [],
      "source": [
        "#storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "storeResults('Logistic Regression',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U7plPv8taAXe",
      "metadata": {
        "id": "U7plPv8taAXe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "94a3a5bf",
      "metadata": {
        "id": "94a3a5bf"
      },
      "source": [
        "## 5.2. K-Nearest Neighbors : Classifier\n",
        "\n",
        "K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique. K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcdb78be",
      "metadata": {
        "id": "fcdb78be"
      },
      "outputs": [],
      "source": [
        "# K-Nearest Neighbors Classifier model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# instantiate the model\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "# fit the model\n",
        "knn.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269c61e7",
      "metadata": {
        "id": "269c61e7"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_train_knn = knn.predict(X_train)\n",
        "y_test_knn = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d9c3bf",
      "metadata": {
        "id": "77d9c3bf"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy,f1_score,Recall,precision of the model performance\n",
        "\n",
        "acc_train_knn = metrics.accuracy_score(y_train,y_train_knn)\n",
        "acc_test_knn = metrics.accuracy_score(y_test,y_test_knn)\n",
        "print(\"K-Nearest Neighbors : Accuracy on training Data: {:.3f}\".format(acc_train_knn))\n",
        "print(\"K-Nearest Neighbors : Accuracy on test Data: {:.3f}\".format(acc_test_knn))\n",
        "print()\n",
        "\n",
        "f1_score_train_knn = metrics.f1_score(y_train,y_train_knn)\n",
        "f1_score_test_knn = metrics.f1_score(y_test,y_test_knn)\n",
        "print(\"K-Nearest Neighbors : f1_score on training Data: {:.3f}\".format(f1_score_train_knn))\n",
        "print(\"K-Nearest Neighbors : f1_score on test Data: {:.3f}\".format(f1_score_test_knn))\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "precision_score_train_knn = metrics.precision_score(y_train,y_train_knn)\n",
        "precision_score_test_knn = metrics.precision_score(y_test,y_test_knn)\n",
        "print(\"K-Nearest Neighbors : precision on training Data: {:.3f}\".format(precision_score_train_knn))\n",
        "print(\"K-Nearest Neighbors : precision on test Data: {:.3f}\".format(precision_score_test_knn))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_knn).ravel()\n",
        "tpr_score_train_knn  =  tp / (tp + fn)\n",
        "tnr_score_train_knn  =  tn / (tn + fp)\n",
        "fpr_score_train_knn  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_knn).ravel()\n",
        "tpr_score_test_knn =  tp / (tp + fn)\n",
        "tnr_score_test_knn  =  tn / (tn + fp)\n",
        "fpr_score_test_knn  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_knn))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_knn))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_knn))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_knn))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_knn))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_knn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pqaWUBVK219n",
      "metadata": {
        "id": "pqaWUBVK219n"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "    # fit the model\n",
        "    knn.fit(X_train,y_train)\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_knn_fold = knn.predict(X_test_fold)\n",
        "    y_train_knn_fold =  knn.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_knn_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_knn_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_knn_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_knn_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_knn_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_knn_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_knn_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_knn_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VCv_K944aEBJ",
      "metadata": {
        "id": "VCv_K944aEBJ"
      },
      "outputs": [],
      "source": [
        "!pip install joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QxpikLvWaxSb",
      "metadata": {
        "id": "QxpikLvWaxSb"
      },
      "outputs": [],
      "source": [
        "# Assuming 'knn_model' is your trained KNN model\n",
        "import joblib\n",
        "joblib.dump(knn, 'knn_model.pkl')\n",
        "\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download('knn_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IPENaLs434hy",
      "metadata": {
        "id": "IPENaLs434hy"
      },
      "outputs": [],
      "source": [
        "print(\"knn\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6a6658f",
      "metadata": {
        "id": "f6a6658f"
      },
      "outputs": [],
      "source": [
        "#computing the classification report of the model\n",
        "\n",
        "print(metrics.classification_report(y_test, y_test_knn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4dc5c1b",
      "metadata": {
        "id": "d4dc5c1b"
      },
      "outputs": [],
      "source": [
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "# try max_depth from 1 to 20\n",
        "depth = range(1,20)\n",
        "for n in depth:\n",
        "    knn = KNeighborsClassifier(n_neighbors=n)\n",
        "\n",
        "    knn.fit(X_train, y_train)\n",
        "    # record training set accuracy\n",
        "    training_accuracy.append(knn.score(X_train, y_train))\n",
        "    # record generalization accuracy\n",
        "    test_accuracy.append(knn.score(X_test, y_test))\n",
        "\n",
        "\n",
        "#plotting the training & testing accuracy for n_estimators from 1 to 20\n",
        "plt.plot(depth, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(depth, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"n_neighbors\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e5bf0c",
      "metadata": {
        "id": "19e5bf0c"
      },
      "outputs": [],
      "source": [
        "#storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "storeResults('K-Nearest Neighbors',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8bc8b53",
      "metadata": {
        "id": "b8bc8b53"
      },
      "source": [
        "## 5.3. Support Vector Machine : Classifier\n",
        "\n",
        "Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3cb194",
      "metadata": {
        "id": "be3cb194"
      },
      "outputs": [],
      "source": [
        "# Support Vector Classifier model\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'gamma': [0.1],'kernel': ['rbf','linear']}\n",
        "\n",
        "svc = GridSearchCV(SVC(), param_grid)\n",
        "\n",
        "# fitting the model for grid search\n",
        "svc.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b25eef4",
      "metadata": {
        "id": "2b25eef4"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_train_svc = svc.predict(X_train)\n",
        "y_test_svc = svc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079d4b39",
      "metadata": {
        "id": "079d4b39"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_svc = metrics.accuracy_score(y_train,y_train_svc)\n",
        "acc_test_svc = metrics.accuracy_score(y_test,y_test_svc)\n",
        "print(\"Support Vector Machine : Accuracy on training Data: {:.3f}\".format(acc_train_svc))\n",
        "print(\"Support Vector Machine : Accuracy on test Data: {:.3f}\".format(acc_test_svc))\n",
        "print()\n",
        "\n",
        "f1_score_train_svc = metrics.f1_score(y_train,y_train_svc)\n",
        "f1_score_test_svc = metrics.f1_score(y_test,y_test_svc)\n",
        "print(\"Support Vector Machine : f1_score on training Data: {:.3f}\".format(f1_score_train_svc))\n",
        "print(\"Support Vector Machine : f1_score on test Data: {:.3f}\".format(f1_score_test_svc))\n",
        "print()\n",
        "\n",
        "precision_score_train_svc = metrics.precision_score(y_train,y_train_svc)\n",
        "precision_score_test_svc = metrics.precision_score(y_test,y_test_svc)\n",
        "print(\"Support Vector Machine : precision on training Data: {:.3f}\".format(precision_score_train_svc))\n",
        "print(\"Support Vector Machine : precision on test Data: {:.3f}\".format(precision_score_test_svc))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_svc).ravel()\n",
        "tpr_score_train_svc  =  tp / (tp + fn)\n",
        "tnr_score_train_svc  =  tn / (tn + fp)\n",
        "fpr_score_train_svc  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_svc).ravel()\n",
        "tpr_score_test_svc  =  tp / (tp + fn)\n",
        "tnr_score_test_svc  =  tn / (tn + fp)\n",
        "fpr_score_test_svc  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_svc))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_svc))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_svc))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_svc))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_svc))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_svc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OdnbkrPLpfnS",
      "metadata": {
        "id": "OdnbkrPLpfnS"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    param_grid = {'gamma': [0.1],'kernel': ['rbf','linear']}\n",
        "\n",
        "    svc = GridSearchCV(SVC(), param_grid)\n",
        "    svc.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_svc_fold = svc.predict(X_test_fold)\n",
        "    y_train_svc_fold =  svc.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_svc_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_svc_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_svc_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_svc_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_svc_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_svc_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_svc_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_svc_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PZl0J2X5pgj8",
      "metadata": {
        "id": "PZl0J2X5pgj8"
      },
      "outputs": [],
      "source": [
        "print(\"svc\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35U-_eBJpoz5",
      "metadata": {
        "id": "35U-_eBJpoz5"
      },
      "outputs": [],
      "source": [
        "#storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "storeResults('Support Vector Machine',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ba22f40",
      "metadata": {
        "id": "8ba22f40"
      },
      "source": [
        "## 5.4. Naive Bayes : Classifier\n",
        "\n",
        "Nave Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.It is mainly used in text, image classification that includes a high-dimensional training dataset. Nave Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69469f59",
      "metadata": {
        "id": "69469f59"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes Classifier Model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# instantiate the model\n",
        "nb=  GaussianNB()\n",
        "\n",
        "# fit the model\n",
        "nb.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5af1028",
      "metadata": {
        "id": "d5af1028"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_train_nb = nb.predict(X_train)\n",
        "y_test_nb = nb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63968c7a",
      "metadata": {
        "id": "63968c7a"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_nb = metrics.accuracy_score(y_train,y_train_nb)\n",
        "acc_test_nb = metrics.accuracy_score(y_test,y_test_nb)\n",
        "print(\"Naive Bayes Classifier : Accuracy on training Data: {:.3f}\".format(acc_train_nb))\n",
        "print(\"Naive Bayes Classifier : Accuracy on test Data: {:.3f}\".format(acc_test_nb))\n",
        "print()\n",
        "\n",
        "f1_score_train_nb = metrics.f1_score(y_train,y_train_nb)\n",
        "f1_score_test_nb = metrics.f1_score(y_test,y_test_nb)\n",
        "print(\"Naive Bayes Classifier : f1_score on training Data: {:.3f}\".format(f1_score_train_nb))\n",
        "print(\"Naive Bayes Classifier : f1_score on test Data: {:.3f}\".format(f1_score_test_nb))\n",
        "print()\n",
        "\n",
        "precision_score_train_nb = metrics.precision_score(y_train,y_train_nb)\n",
        "precision_score_test_nb = metrics.precision_score(y_test,y_test_nb)\n",
        "print(\"Naive Bayes Classifier : precision on training Data: {:.3f}\".format(precision_score_train_nb))\n",
        "print(\"Naive Bayes Classifier : precision on test Data: {:.3f}\".format(precision_score_test_nb))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_nb).ravel()\n",
        "tpr_score_train_nb  =  tp / (tp + fn)\n",
        "tnr_score_train_nb  =  tn / (tn + fp)\n",
        "fpr_score_train_nb =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_nb).ravel()\n",
        "tpr_score_test_nb  =  tp / (tp + fn)\n",
        "tnr_score_test_nb  =  tn / (tn + fp)\n",
        "fpr_score_test_nb  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_nb))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_nb))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_nb))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_nb))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_nb))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_nb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bZMkjaFUvg8y",
      "metadata": {
        "id": "bZMkjaFUvg8y"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    nb = GaussianNB()\n",
        "\n",
        "    # fit the model\n",
        "    nb.fit(X_train_fold,y_train_fold)\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_nb_fold = nb.predict(X_test_fold)\n",
        "    y_train_nb_fold =  nb.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_nb_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_nb_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_nb_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_nb_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_nb_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_nb_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_nb_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_nb_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-f-kW6YA3_sO",
      "metadata": {
        "id": "-f-kW6YA3_sO"
      },
      "outputs": [],
      "source": [
        "print(\"nb\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb7d8f0b",
      "metadata": {
        "id": "cb7d8f0b"
      },
      "outputs": [],
      "source": [
        "#computing the classification report of the model\n",
        "\n",
        "print(metrics.classification_report(y_test, y_test_nb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51080f01",
      "metadata": {
        "id": "51080f01"
      },
      "outputs": [],
      "source": [
        "##storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "#storeResults('Naive Bayes Classifier',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bffea1bb",
      "metadata": {
        "id": "bffea1bb"
      },
      "source": [
        "## 5.5. Decision Trees : Classifier\n",
        "\n",
        "Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31379c27",
      "metadata": {
        "id": "31379c27"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Classifier model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# instantiate the model\n",
        "tree = DecisionTreeClassifier(max_depth=30)\n",
        "\n",
        "# fit the model\n",
        "tree.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c19c3ec",
      "metadata": {
        "id": "6c19c3ec"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "\n",
        "y_train_tree = tree.predict(X_train)\n",
        "y_test_tree = tree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b577d598",
      "metadata": {
        "id": "b577d598"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_tree = metrics.accuracy_score(y_train,y_train_tree)\n",
        "acc_test_tree = metrics.accuracy_score(y_test,y_test_tree)\n",
        "print(\"Decision Tree : Accuracy on training Data: {:.3f}\".format(acc_train_tree))\n",
        "print(\"Decision Tree : Accuracy on test Data: {:.3f}\".format(acc_test_tree))\n",
        "print()\n",
        "\n",
        "f1_score_train_tree = metrics.f1_score(y_train,y_train_tree)\n",
        "f1_score_test_tree = metrics.f1_score(y_test,y_test_tree)\n",
        "print(\"Decision Tree : f1_score on training Data: {:.3f}\".format(f1_score_train_tree))\n",
        "print(\"Decision Tree : f1_score on test Data: {:.3f}\".format(f1_score_test_tree))\n",
        "print()\n",
        "\n",
        "\n",
        "precision_score_train_tree = metrics.precision_score(y_train,y_train_tree)\n",
        "precision_score_test_tree = metrics.precision_score(y_test,y_test_tree)\n",
        "print(\"Decision Tree : precision on training Data: {:.3f}\".format(precision_score_train_tree))\n",
        "print(\"Decision Tree : precision on test Data: {:.3f}\".format(precision_score_test_tree))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_tree).ravel()\n",
        "tpr_score_train_tree  =  tp / (tp + fn)\n",
        "tnr_score_train_tree  =  tn / (tn + fp)\n",
        "fpr_score_train_tree  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_tree).ravel()\n",
        "tpr_score_test_tree  =  tp / (tp + fn)\n",
        "tnr_score_test_tree =  tn / (tn + fp)\n",
        "fpr_score_test_tree =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_tree))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_tree))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_tree))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_tree))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_tree))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_tree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nSBNdbovvAYw",
      "metadata": {
        "id": "nSBNdbovvAYw"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    tree = DecisionTreeClassifier(max_depth=30)\n",
        "\n",
        "\n",
        "    # fit the model\n",
        "    tree.fit(X_train_fold,y_train_fold)\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_tree_fold = tree.predict(X_test_fold)\n",
        "    y_train_tree_fold =  tree.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_tree_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_tree_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_tree_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_tree_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_tree_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_tree_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_tree_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_tree_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Itig2JOm4CJX",
      "metadata": {
        "id": "Itig2JOm4CJX"
      },
      "outputs": [],
      "source": [
        "print(\"tree\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bcb8b6",
      "metadata": {
        "id": "87bcb8b6"
      },
      "outputs": [],
      "source": [
        "#computing the classification report of the model\n",
        "\n",
        "print(metrics.classification_report(y_test, y_test_tree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0fdcdd9",
      "metadata": {
        "id": "b0fdcdd9"
      },
      "outputs": [],
      "source": [
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "# try max_depth from 1 to 30\n",
        "depth = range(1,30)\n",
        "for n in depth:\n",
        "    tree_test = DecisionTreeClassifier(max_depth=n)\n",
        "\n",
        "    tree_test.fit(X_train, y_train)\n",
        "    # record training set accuracy\n",
        "    training_accuracy.append(tree_test.score(X_train, y_train))\n",
        "    # record generalization accuracy\n",
        "    test_accuracy.append(tree_test.score(X_test, y_test))\n",
        "\n",
        "\n",
        "#plotting the training & testing accuracy for max_depth from 1 to 30\n",
        "plt.plot(depth, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(depth, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3b12b8",
      "metadata": {
        "id": "0f3b12b8"
      },
      "outputs": [],
      "source": [
        "#storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "storeResults('Decision Tree',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02637ba8",
      "metadata": {
        "id": "02637ba8"
      },
      "source": [
        "## 5.6. Random Forest : Classifier\n",
        "\n",
        "Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49272c25",
      "metadata": {
        "id": "49272c25"
      },
      "outputs": [],
      "source": [
        "# Random Forest Classifier Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# instantiate the model\n",
        "forest = RandomForestClassifier(n_estimators=10)\n",
        "\n",
        "# fit the model\n",
        "forest.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c1f8b7",
      "metadata": {
        "id": "82c1f8b7"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_train_forest = forest.predict(X_train)\n",
        "y_test_forest = forest.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41bd7f0",
      "metadata": {
        "id": "a41bd7f0"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_forest = metrics.accuracy_score(y_train,y_train_forest)\n",
        "acc_test_forest = metrics.accuracy_score(y_test,y_test_forest)\n",
        "print(\"Random Forest : Accuracy on training Data: {:.3f}\".format(acc_train_forest))\n",
        "print(\"Random Forest : Accuracy on test Data: {:.3f}\".format(acc_test_forest))\n",
        "print()\n",
        "\n",
        "f1_score_train_forest = metrics.f1_score(y_train,y_train_forest)\n",
        "f1_score_test_forest = metrics.f1_score(y_test,y_test_forest)\n",
        "print(\"Random Forest : f1_score on training Data: {:.3f}\".format(f1_score_train_forest))\n",
        "print(\"Random Forest : f1_score on test Data: {:.3f}\".format(f1_score_test_forest))\n",
        "print()\n",
        "\n",
        "\n",
        "precision_score_train_forest = metrics.precision_score(y_train,y_train_forest)\n",
        "precision_score_test_forest = metrics.precision_score(y_test,y_test_tree)\n",
        "print(\"Random Forest : precision on training Data: {:.3f}\".format(precision_score_train_forest))\n",
        "print(\"Random Forest : precision on test Data: {:.3f}\".format(precision_score_test_forest))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_forest).ravel()\n",
        "tpr_score_train_forest  =  tp / (tp + fn)\n",
        "tnr_score_train_forest  =  tn / (tn + fp)\n",
        "fpr_score_train_forest  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_forest).ravel()\n",
        "tpr_score_test_forest  =  tp / (tp + fn)\n",
        "tnr_score_test_forest  =  tn / (tn + fp)\n",
        "fpr_score_test_forest  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_forest))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_forest))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_forest))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_forest))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_forest))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_forest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U--bDgPFuc_A",
      "metadata": {
        "id": "U--bDgPFuc_A"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    forest = RandomForestClassifier(n_estimators = 10)\n",
        "\n",
        "\n",
        "    # fit the model\n",
        "    forest.fit(X_train_fold,y_train_fold)\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_forest_fold = forest.predict(X_test_fold)\n",
        "    y_train_forest_fold =  forest.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_forest_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_forest_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_forest_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_forest_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_forest_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_forest_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_forest_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_forest_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VfgwLqe-4FM4",
      "metadata": {
        "id": "VfgwLqe-4FM4"
      },
      "outputs": [],
      "source": [
        "print(\"forest\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb33464b",
      "metadata": {
        "id": "fb33464b"
      },
      "outputs": [],
      "source": [
        "#computing the classification report of the model\n",
        "\n",
        "print(metrics.classification_report(y_test, y_test_forest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f10c481",
      "metadata": {
        "id": "4f10c481"
      },
      "outputs": [],
      "source": [
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "# try max_depth from 1 to 20\n",
        "depth = range(1,20)\n",
        "for n in depth:\n",
        "    forest_test =  RandomForestClassifier(n_estimators=n)\n",
        "\n",
        "    forest_test.fit(X_train, y_train)\n",
        "    # record training set accuracy\n",
        "    training_accuracy.append(forest_test.score(X_train, y_train))\n",
        "    # record generalization accuracy\n",
        "    test_accuracy.append(forest_test.score(X_test, y_test))\n",
        "\n",
        "\n",
        "#plotting the training & testing accuracy for n_estimators from 1 to 20\n",
        "plt.figure(figsize=None)\n",
        "plt.plot(depth, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(depth, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"n_estimators\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "310a4d15",
      "metadata": {
        "id": "310a4d15"
      },
      "outputs": [],
      "source": [
        "#storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "storeResults('Random Forest',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08ba9a1a",
      "metadata": {
        "id": "08ba9a1a"
      },
      "source": [
        "## 5.7.Gradient Boosting Classifier\n",
        "Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model. Decision trees are usually used when doing gradient boosting. Boosting algorithms play a crucial role in dealing with bias variance trade-off.  Unlike bagging algorithms, which only controls for high variance in a model, boosting controls both the aspects (bias & variance), and is considered to be more effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46672600",
      "metadata": {
        "id": "46672600"
      },
      "outputs": [],
      "source": [
        "# Gradient Boosting Classifier Model\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# instantiate the model\n",
        "gbc = GradientBoostingClassifier(max_depth=4,learning_rate=0.7)\n",
        "\n",
        "# fit the model\n",
        "gbc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1abd4a9e",
      "metadata": {
        "id": "1abd4a9e"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_train_gbc = gbc.predict(X_train)\n",
        "y_test_gbc = gbc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8ea93d",
      "metadata": {
        "id": "4c8ea93d"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_gbc = metrics.accuracy_score(y_train,y_train_gbc)\n",
        "acc_test_gbc = metrics.accuracy_score(y_test,y_test_gbc)\n",
        "print(\"Gradient Boosting Classifier : Accuracy on training Data: {:.3f}\".format(acc_train_gbc))\n",
        "print(\"Gradient Boosting Classifier : Accuracy on test Data: {:.3f}\".format(acc_test_gbc))\n",
        "print()\n",
        "\n",
        "f1_score_train_gbc = metrics.f1_score(y_train,y_train_gbc)\n",
        "f1_score_test_gbc = metrics.f1_score(y_test,y_test_gbc)\n",
        "print(\"Gradient Boosting Classifier : f1_score on training Data: {:.3f}\".format(f1_score_train_gbc))\n",
        "print(\"Gradient Boosting Classifier : f1_score on test Data: {:.3f}\".format(f1_score_test_gbc))\n",
        "print()\n",
        "\n",
        "\n",
        "precision_score_train_gbc = metrics.precision_score(y_train,y_train_gbc)\n",
        "precision_score_test_gbc = metrics.precision_score(y_test,y_test_gbc)\n",
        "print(\"Gradient Boosting Classifier : precision on training Data: {:.3f}\".format(precision_score_train_gbc))\n",
        "print(\"Gradient Boosting Classifier : precision on test Data: {:.3f}\".format(precision_score_test_gbc))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_gbc).ravel()\n",
        "tpr_score_train_gbc  =  tp / (tp + fn)\n",
        "tnr_score_train_gbc  =  tn / (tn + fp)\n",
        "fpr_score_train_gbc  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_gbc).ravel()\n",
        "tpr_score_test_gbc  =  tp / (tp + fn)\n",
        "tnr_score_test_gbc  =  tn / (tn + fp)\n",
        "fpr_score_test_gbc  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_gbc))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_gbc))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_gbc))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_gbc))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_gbc))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_gbc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lmmmvsYYt3Ty",
      "metadata": {
        "id": "lmmmvsYYt3Ty"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    gbc = GradientBoostingClassifier(max_depth=4,learning_rate=0.7)\n",
        "\n",
        "\n",
        "    # fit the model\n",
        "    gbc.fit(X_train_fold,y_train_fold)\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_gbc_fold = gbc.predict(X_test_fold)\n",
        "    y_train_gbc_fold =  gbc.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_gbc_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_gbc_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_gbc_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_gbc_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_gbc_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_gbc_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_gbc_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_gbc_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HByaP1JH4IY8",
      "metadata": {
        "id": "HByaP1JH4IY8"
      },
      "outputs": [],
      "source": [
        "print(\"gbcBoost\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7959d8",
      "metadata": {
        "id": "1f7959d8"
      },
      "outputs": [],
      "source": [
        "#computing the classification report of the model\n",
        "\n",
        "print(metrics.classification_report(y_test, y_test_gbc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e310444",
      "metadata": {
        "id": "7e310444"
      },
      "outputs": [],
      "source": [
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "# try learning_rate from 0.1 to 0.9\n",
        "depth = range(1,10)\n",
        "for n in depth:\n",
        "    forest_test =  GradientBoostingClassifier(learning_rate = n*0.1)\n",
        "\n",
        "    forest_test.fit(X_train, y_train)\n",
        "    # record training set accuracy\n",
        "    training_accuracy.append(forest_test.score(X_train, y_train))\n",
        "    # record generalization accuracy\n",
        "    test_accuracy.append(forest_test.score(X_test, y_test))\n",
        "\n",
        "\n",
        "#plotting the training & testing accuracy for n_estimators from 1 to 50\n",
        "plt.figure(figsize=None)\n",
        "plt.plot(depth, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(depth, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"learning_rate\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c07912f",
      "metadata": {
        "id": "2c07912f"
      },
      "outputs": [],
      "source": [
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "# try learning_rate from 0.1 to 0.9\n",
        "depth = range(1,10,1)\n",
        "for n in depth:\n",
        "    forest_test =  GradientBoostingClassifier(max_depth=n,learning_rate = 0.7)\n",
        "\n",
        "    forest_test.fit(X_train, y_train)\n",
        "    # record training set accuracy\n",
        "    training_accuracy.append(forest_test.score(X_train, y_train))\n",
        "    # record generalization accuracy\n",
        "    test_accuracy.append(forest_test.score(X_test, y_test))\n",
        "\n",
        "\n",
        "#plotting the training & testing accuracy for n_estimators from 1 to 50\n",
        "plt.figure(figsize=None)\n",
        "plt.plot(depth, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(depth, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660fe8b1",
      "metadata": {
        "id": "660fe8b1"
      },
      "outputs": [],
      "source": [
        "#storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "storeResults('Gradient Boosting Classifier',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6820aa6",
      "metadata": {
        "id": "c6820aa6"
      },
      "source": [
        "## 5.8. CatBoost Classifier\n",
        "\n",
        "CatBoost is a recently open-sourced machine learning algorithm from Yandex. It can easily integrate with deep learning frameworks like Googles TensorFlow and Apples Core ML. It can work with diverse data types to help solve a wide range of problems that businesses face today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p9wnyIneczvL",
      "metadata": {
        "id": "p9wnyIneczvL"
      },
      "outputs": [],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387e3c57",
      "metadata": {
        "id": "387e3c57"
      },
      "outputs": [],
      "source": [
        "#  catboost Classifier Model\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# instantiate the model\n",
        "cat = CatBoostClassifier(learning_rate  = 0.1)\n",
        "\n",
        "# fit the model\n",
        "cat.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2353cb47",
      "metadata": {
        "id": "2353cb47"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_train_cat = cat.predict(X_train)\n",
        "y_test_cat = cat.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6cc2cf5",
      "metadata": {
        "id": "d6cc2cf5"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_cat  = metrics.accuracy_score(y_train,y_train_cat)\n",
        "acc_test_cat = metrics.accuracy_score(y_test,y_test_cat)\n",
        "print(\"CatBoost Classifier : Accuracy on training Data: {:.3f}\".format(acc_train_cat))\n",
        "print(\"CatBoost Classifier : Accuracy on test Data: {:.3f}\".format(acc_test_cat))\n",
        "print()\n",
        "\n",
        "f1_score_train_cat = metrics.f1_score(y_train,y_train_cat)\n",
        "f1_score_test_cat = metrics.f1_score(y_test,y_test_cat)\n",
        "print(\"CatBoost Classifier : f1_score on training Data: {:.3f}\".format(f1_score_train_cat))\n",
        "print(\"CatBoost Classifier : f1_score on test Data: {:.3f}\".format(f1_score_test_cat))\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "precision_score_train_cat = metrics.precision_score(y_train,y_train_cat)\n",
        "precision_score_test_cat = metrics.precision_score(y_test,y_test_cat)\n",
        "print(\"CatBoost Classifier : precision on training Data: {:.3f}\".format(precision_score_train_cat))\n",
        "print(\"CatBoost Classifier : precision on test Data: {:.3f}\".format(precision_score_test_cat))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_cat).ravel()\n",
        "tpr_score_train_cat  =  tp / (tp + fn)\n",
        "tnr_score_train_cat  =  tn / (tn + fp)\n",
        "fpr_score_train_cat  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_cat).ravel()\n",
        "tpr_score_test_cat  =  tp / (tp + fn)\n",
        "tnr_score_test_cat  =  tn / (tn + fp)\n",
        "fpr_score_test_cat  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_cat))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_cat))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_cat))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_cat))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_cat))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b88154b6",
      "metadata": {
        "id": "b88154b6"
      },
      "outputs": [],
      "source": [
        "#computing the classification report of the model\n",
        "\n",
        "print(metrics.classification_report(y_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e56e3618",
      "metadata": {
        "id": "e56e3618"
      },
      "outputs": [],
      "source": [
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "# try learning_rate from 0.1 to 0.9\n",
        "depth = range(1,10)\n",
        "for n in depth:\n",
        "    forest_test =  CatBoostClassifier(learning_rate = n*0.1)\n",
        "\n",
        "    forest_test.fit(X_train, y_train)\n",
        "    # record training set accuracy\n",
        "    training_accuracy.append(forest_test.score(X_train, y_train))\n",
        "    # record generalization accuracy\n",
        "    test_accuracy.append(forest_test.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d13ba8",
      "metadata": {
        "id": "53d13ba8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#plotting the training & testing accuracy for n_estimators from 1 to 50\n",
        "plt.figure(figsize=None)\n",
        "plt.plot(depth, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(depth, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"learning_rate\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2vvSA-HitH_s",
      "metadata": {
        "id": "2vvSA-HitH_s"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    cat = CatBoostClassifier(learning_rate = 0.1)\n",
        "\n",
        "\n",
        "    # fit the model\n",
        "    cat.fit(X_train_fold,y_train_fold)\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_cat_fold = cat.predict(X_test_fold)\n",
        "    y_train_cat_fold =  cat.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_cat_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_cat_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_cat_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_cat_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_cat_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_cat_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_cat_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_cat_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rA6BtTZV4LfM",
      "metadata": {
        "id": "rA6BtTZV4LfM"
      },
      "outputs": [],
      "source": [
        "print(\"CatBoost\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080959b7",
      "metadata": {
        "id": "080959b7"
      },
      "outputs": [],
      "source": [
        "#storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "storeResults('CatBoost Classifier',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87f8a55",
      "metadata": {
        "id": "c87f8a55"
      },
      "source": [
        "## 5.9. Multi-layer Perceptron classifier\n",
        "\n",
        "rnnClassifier stands for Multi-layer Perceptron classifier which in the name itself connects to a Neural Network. Unlike other classification algorithms such as Support Vectors or Naive Bayes Classifier, MLPClassifier relies on an underlying Neural Network to perform the task of classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bfc3ea7",
      "metadata": {
        "id": "5bfc3ea7"
      },
      "outputs": [],
      "source": [
        "# Multi-layer Perceptron Classifier Model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# instantiate the model\n",
        "mlp = MLPClassifier()\n",
        "#mlp = GridSearchCV(mlpc, parameter_space)\n",
        "\n",
        "# fit the model\n",
        "mlp.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf7f1af",
      "metadata": {
        "id": "2cf7f1af"
      },
      "outputs": [],
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_train_mlp = mlp.predict(X_train)\n",
        "y_test_mlp = mlp.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68aa680",
      "metadata": {
        "id": "d68aa680"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "\n",
        "acc_train_mlp  = metrics.accuracy_score(y_train,y_train_mlp)\n",
        "acc_test_mlp = metrics.accuracy_score(y_test,y_test_mlp)\n",
        "print(\"Multi-layer Perceptron : Accuracy on training Data: {:.3f}\".format(acc_train_mlp))\n",
        "print(\"Multi-layer Perceptron : Accuracy on test Data: {:.3f}\".format(acc_test_mlp))\n",
        "print()\n",
        "\n",
        "f1_score_train_mlp = metrics.f1_score(y_train,y_train_mlp)\n",
        "f1_score_test_mlp = metrics.f1_score(y_test,y_test_mlp)\n",
        "print(\"Multi-layer Perceptron : f1_score on training Data: {:.3f}\".format(f1_score_train_mlp))\n",
        "print(\"Multi-layer Perceptron : f1_score on test Data: {:.3f}\".format(f1_score_train_mlp))\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "precision_score_train_mlp = metrics.precision_score(y_train,y_train_mlp)\n",
        "precision_score_test_mlp = metrics.precision_score(y_test,y_test_mlp)\n",
        "print(\"Multi-layer Perceptron : precision on training Data: {:.3f}\".format(precision_score_train_mlp))\n",
        "print(\"Multi-layer Perceptron : precision on test Data: {:.3f}\".format(precision_score_test_mlp))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_mlp).ravel()\n",
        "tpr_score_train_mlp  =  tp / (tp + fn)\n",
        "tnr_score_train_mlp  =  tn / (tn + fp)\n",
        "fpr_score_train_mlp  =  fp / (fp + tn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_mlp).ravel()\n",
        "tpr_score_test_mlp  =  tp / (tp + fn)\n",
        "tnr_score_test_mlp  =  tn / (tn + fp)\n",
        "fpr_score_test_mlp  =  fp / (fp + tn)\n",
        "\n",
        "print(\"tpr on training Data: {:.3f}\".format(tpr_score_train_mlp))\n",
        "print(\"tpr on test Data: {:.3f}\".format(tpr_score_test_mlp))\n",
        "print()\n",
        "print(\"tnr on training Data: {:.3f}\".format(tnr_score_train_mlp))\n",
        "print(\"tnr on test Data: {:.3f}\".format(tnr_score_test_mlp))\n",
        "print()\n",
        "print(\"fpr on training Data: {:.3f}\".format(fpr_score_train_mlp))\n",
        "print(\"fpr on test Data: {:.3f}\".format(fpr_score_test_mlp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0EANLvVesHp5",
      "metadata": {
        "id": "0EANLvVesHp5"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # instantiate the model\n",
        "    mlp = MLPClassifier()\n",
        "    #mlp = GridSearchCV(mlpc, parameter_space)\n",
        "\n",
        "    # fit the model\n",
        "    mlp.fit(X_train_fold,y_train_fold)\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "\n",
        "    y_test_mlp_fold = mlp.predict(X_test_fold)\n",
        "    y_train_mlp_fold =  mlp.predict(X_train_fold)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_mlp_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_mlp_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_mlp_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_mlp_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_mlp_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_mlp_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_mlp_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_mlp_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UxE3aAKl4Nwm",
      "metadata": {
        "id": "UxE3aAKl4Nwm"
      },
      "outputs": [],
      "source": [
        "print(\"MLP\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_test_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"max fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"max fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8983b248",
      "metadata": {
        "id": "8983b248"
      },
      "outputs": [],
      "source": [
        "##storing the results. The below mentioned order of parameter passing is important.\n",
        "\n",
        "#storeResults('Multi-layer Perceptron',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cef57ca",
      "metadata": {
        "id": "2cef57ca"
      },
      "source": [
        "## 6. Comparision of Models\n",
        "To compare the models performance, a dataframe is created. The columns of this dataframe are the lists created to store the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcddf7ae",
      "metadata": {
        "id": "bcddf7ae"
      },
      "outputs": [],
      "source": [
        "#creating dataframe\n",
        "result = pd.DataFrame({ 'ML Model' : ML_Model,\n",
        "                        'Avg_Accuracy' : avg_accuracy,\n",
        "                        'max_Accuracy' : max_accuracy,\n",
        "                        'avg_f1_score' : avg_f1_score,\n",
        "                        'max_f1_score' : max_f1_score,\n",
        "                        'avg_Precision': avg_precision,\n",
        "                        'max_Precision': max_precision,\n",
        "                        'avg_tpr':avg_tpr,\n",
        "                        'max_tpr':max_tpr,\n",
        "                        'avg_tnr':avg_tnr,\n",
        "                        'max_tnr':max_tnr,\n",
        "                        'avg_fpr':avg_fpr,\n",
        "                        'max_fpr':max_fpr,\n",
        "                      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6851e518",
      "metadata": {
        "id": "6851e518"
      },
      "outputs": [],
      "source": [
        "# dispalying total result\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ec314b",
      "metadata": {
        "id": "b5ec314b"
      },
      "outputs": [],
      "source": [
        "#Sorting the datafram on accuracy\n",
        "sorted_result=result.sort_values(by=['avg_tpr', 'avg_f1_score'],ascending=False).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf364ad6",
      "metadata": {
        "id": "bf364ad6"
      },
      "outputs": [],
      "source": [
        "# dispalying total result\n",
        "sorted_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JdoTb0VZTJM4",
      "metadata": {
        "id": "JdoTb0VZTJM4"
      },
      "source": [
        "# 7. RNN based models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2WQauHcT3lY",
      "metadata": {
        "id": "d2WQauHcT3lY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ssm61yUWTYks",
      "metadata": {
        "id": "Ssm61yUWTYks"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "# Build RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(64, input_shape=(13, 1)),  # 64 units in the RNN layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predictions_train = model.predict(X_train)\n",
        "\n",
        "# Convert the predictions to binary labels (0 or 1) based on a threshold (e.g., 0.5 for sigmoid activation)\n",
        "y_test_rnn = (predictions > 0.5).astype(int)\n",
        "y_train_rnn = (predictions_train > 0.5).astype(int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HWEq7kcgpvZR",
      "metadata": {
        "id": "HWEq7kcgpvZR"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FeF3IGHJVnlX",
      "metadata": {
        "id": "FeF3IGHJVnlX"
      },
      "outputs": [],
      "source": [
        "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
        "acc_train_fold =[]\n",
        "acc_test_fold=[]\n",
        "f1_score_train_fold=[]\n",
        "f1_score_test_fold=[]\n",
        "precision_score_train_fold=[]\n",
        "precision_score_test_fold=[]\n",
        "tpr_score_train_fold=[]\n",
        "tnr_score_train_fold=[]\n",
        "fpr_score_train_fold = []\n",
        "tpr_score_test_fold=[]\n",
        "tnr_score_test_fold=[]\n",
        "fpr_score_test_fold=[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Build the RNN model\n",
        "    model = Sequential([\n",
        "        SimpleRNN(64, input_shape=(13, 1)),  # 64 units in the RNN layer\n",
        "        Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    predictions_fold = model.predict(X_test_fold)\n",
        "    predictions_train_fold = model.predict(X_train_fold)\n",
        "    y_test_rnn_fold = (predictions_fold > 0.5).astype(int)\n",
        "    y_train_rnn_fold = (predictions_train_fold > 0.5).astype(int)\n",
        "\n",
        "\n",
        "    acc_train_fold.append(metrics.accuracy_score(y_train_fold,y_train_rnn_fold))\n",
        "    acc_test_fold.append(metrics.accuracy_score(y_test_fold,y_test_rnn_fold))\n",
        "\n",
        "\n",
        "    f1_score_train_fold.append(metrics.f1_score(y_train_fold,y_train_rnn_fold))\n",
        "    f1_score_test_fold.append(metrics.f1_score(y_test_fold,y_test_rnn_fold))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision_score_train_fold.append(metrics.precision_score(y_train_fold,y_train_rnn_fold))\n",
        "    precision_score_test_fold.append(metrics.precision_score(y_test_fold,y_test_rnn_fold))\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_train_fold, y_train_rnn_fold).ravel()\n",
        "    tpr_score_train_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_train_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_train_fold  .append(fp / (fp + tn))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_fold, y_test_rnn_fold).ravel()\n",
        "    tpr_score_test_fold  .append(tp / (tp + fn))\n",
        "    tnr_score_test_fold  .append(tn / (tn + fp))\n",
        "    fpr_score_test_fold  .append(fp / (fp + tn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QA3VmheUr6aE",
      "metadata": {
        "id": "QA3VmheUr6aE"
      },
      "outputs": [],
      "source": [
        "print(\"RNN\")\n",
        "print()\n",
        "\n",
        "print(\"fold : avg Accuracy on training Data: {:.3f}\".format(calculate_average(acc_train_fold)))\n",
        "print(\"fold : avg Accuracy on test Data: {:.3f}\".format(calculate_average(acc_test_fold)))\n",
        "print(\"fold : max Accuracy on training Data: {:.3f}\".format(calculate_max(acc_train_fold)))\n",
        "print(\"fold : max Accuracy on test Data: {:.3f}\".format(calculate_max(acc_test_fold)))\n",
        "print()\n",
        "print(\"fold : avg f1_score on training Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : avg f1_score on test Data: {:.3f}\".format(calculate_average(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on training Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print(\"fold : max f1_score on test Data: {:.3f}\".format(calculate_max(f1_score_train_fold)))\n",
        "print()\n",
        "print(\"fold : avg precision on training Data: {:.3f}\".format(calculate_average(precision_score_train_fold)))\n",
        "print(\"fold : avg precision on test Data: {:.3f}\".format(calculate_average(precision_score_test_fold)))\n",
        "print(\"fold : max precision on training Data: {:.3f}\".format(calculate_max(precision_score_train_fold)))\n",
        "print(\"fold : max precision on test Data: {:.3f}\".format(calculate_max(precision_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tpr on training Data: {:.3f}\".format(calculate_average(tpr_score_train_fold)))\n",
        "print(\"avg tpr on test Data: {:.3f}\".format(calculate_average(tpr_score_test_fold)))\n",
        "print(\"max tpr on training Data: {:.3f}\".format(calculate_max(tpr_score_train_fold)))\n",
        "print(\"max tpr on test Data: {:.3f}\".format(calculate_max(tpr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg tnr on training Data: {:.3f}\".format(calculate_average(tnr_score_train_fold)))\n",
        "print(\"avg tnr on test Data: {:.3f}\".format(calculate_average(tnr_score_test_fold)))\n",
        "print(\"max tnr on training Data: {:.3f}\".format(calculate_max(tnr_score_train_fold)))\n",
        "print(\"max tnr on test Data: {:.3f}\".format(calculate_max(tnr_score_test_fold)))\n",
        "print()\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_average(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_average(fpr_score_test_fold)))\n",
        "print(\"avg fpr on training Data: {:.3f}\".format(calculate_max(fpr_score_train_fold)))\n",
        "print(\"avg fpr on test Data: {:.3f}\".format(calculate_max(fpr_score_test_fold)))\n",
        "\n",
        "a = calculate_average(acc_test_fold)\n",
        "b = calculate_max(acc_test_fold)\n",
        "c = calculate_average(f1_score_train_fold)\n",
        "d = calculate_max(f1_score_test_fold)\n",
        "e = calculate_average(precision_score_test_fold)\n",
        "f = calculate_max(precision_score_test_fold)\n",
        "g = calculate_average(tpr_score_test_fold)\n",
        "h = calculate_max(tpr_score_test_fold)\n",
        "i = calculate_average(tnr_score_test_fold)\n",
        "j = calculate_max(tnr_score_test_fold)\n",
        "k = calculate_average(fpr_score_test_fold)\n",
        "l = calculate_max(fpr_score_test_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x11rNkroeueJ",
      "metadata": {
        "id": "x11rNkroeueJ"
      },
      "outputs": [],
      "source": [
        "storeResults('RNN',a,b,c,d,e,f,g,h,i,j,k,l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BwhvTeCqgnu3",
      "metadata": {
        "id": "BwhvTeCqgnu3"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pBx0eYPJgVGr",
      "metadata": {
        "id": "pBx0eYPJgVGr"
      },
      "outputs": [],
      "source": [
        "sorted_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P77tSdVueMox",
      "metadata": {
        "id": "P77tSdVueMox"
      },
      "outputs": [],
      "source": [
        "# prompt: write coddraw bar graph of each model showing mean and max tpr hig,it with diffrent color and y axis range 90 to 100 do it in percentage\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create data for bar plot\n",
        "model_names = ['Logistic Regression', 'KNN', 'SVM', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'CatBoost']\n",
        "avg_tpr = result['avg_tpr'] * 100\n",
        "max_tpr = result['max_tpr'] * 100\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bar chart with mean and max TPR values\n",
        "width = 0.35\n",
        "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_title('True Positive Rate', fontsize=14)\n",
        "x_pos = np.arange(len(model_names))\n",
        "ax.bar(x_pos, avg_tpr, width, color='lightblue', label='Mean TPR')\n",
        "ax.bar(x_pos + width, max_tpr, width, color='grey', label='Max TPR')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Models', fontsize=12)\n",
        "ax.set_ylabel('True Positive Rate (%)', fontsize=12)\n",
        "ax.set_xticks(x_pos + width / 2)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.legend(loc='upper left')\n",
        "\n",
        "# Set y-axis range\n",
        "ax.set_ylim(80, 100)\n",
        "y_ticks = np.arange(80, 101, 2)  # 0, 2, 4, 6, ...\n",
        "ax.set_yticks(y_ticks)\n",
        "# Add grid and show plot\n",
        "ax.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_3vtbBAsivo8",
      "metadata": {
        "id": "_3vtbBAsivo8"
      },
      "outputs": [],
      "source": [
        "# prompt: write coddraw bar graph of each model showing mean and max tpr hig,it with diffrent color and y axis range 90 to 100 do it in percentage\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create data for bar plot\n",
        "model_names = ['Logistic Regression', 'KNN', 'SVM', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'CatBoost']\n",
        "avg_accuracy = result['Avg_Accuracy'] * 100\n",
        "max_accuracy = result['max_Accuracy'] * 100\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bar chart with mean and max TPR values\n",
        "width = 0.35\n",
        "ax.set_ylabel('Accuracy', fontsize=12)\n",
        "ax.set_title('Accuracy(ACC)', fontsize=14)\n",
        "x_pos = np.arange(len(model_names))\n",
        "ax.bar(x_pos, avg_accuracy, width, color='lightblue', label='Mean Accuracy')\n",
        "ax.bar(x_pos + width, max_accuracy, width, color='grey', label='Max Accuracy')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Models', fontsize=12)\n",
        "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax.set_xticks(x_pos + width / 2)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.legend(loc='upper left')\n",
        "\n",
        "# Set y-axis range\n",
        "ax.set_ylim(0, 100)\n",
        "\n",
        "# Add grid and show plot\n",
        "ax.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nkzgeBP6k2Wb",
      "metadata": {
        "id": "nkzgeBP6k2Wb"
      },
      "outputs": [],
      "source": [
        "# prompt: write coddraw bar graph of each model showing mean and max tpr hig,it with diffrent color and y axis range 90 to 100 do it in percentage\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create data for bar plot\n",
        "model_names = ['Logistic Regression', 'KNN', 'SVM', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'CatBoost']\n",
        "avg_precision = result['avg_Precision'] * 100\n",
        "max_precision = result['max_Precision'] * 100\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bar chart with mean and max TPR values\n",
        "width = 0.35\n",
        "#ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_title('Precision', fontsize=14)\n",
        "x_pos = np.arange(len(model_names))\n",
        "ax.bar(x_pos, avg_precision, width, color='lightblue', label='Mean Precision')\n",
        "ax.bar(x_pos + width, max_precision, width, color='grey', label='Max Precision')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Models', fontsize=12)\n",
        "ax.set_ylabel('Precision (%)', fontsize=12)\n",
        "ax.set_xticks(x_pos + width / 2)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.legend(loc='upper left')\n",
        "\n",
        "# Set y-axis range\n",
        "ax.set_ylim(0, 100)\n",
        "\n",
        "# Add grid and show plot\n",
        "ax.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OUv-u5uImcU8",
      "metadata": {
        "id": "OUv-u5uImcU8"
      },
      "outputs": [],
      "source": [
        "# prompt: write coddraw bar graph of each model showing mean and max tpr hig,it with diffrent color and y axis range 90 to 100 do it in percentage\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create data for bar plot\n",
        "model_names = ['Logistic Regression', 'KNN', 'SVM', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'CatBoost']\n",
        "avg_fpr = result['avg_fpr'] * 100\n",
        "max_fpr = result['max_fpr'] * 100\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bar chart with mean and max TPR values\n",
        "width = 0.35\n",
        "#ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_title('False Positive Rate', fontsize=14)\n",
        "x_pos = np.arange(len(model_names))\n",
        "ax.bar(x_pos, avg_fpr, width, color='lightblue', label='Mean FPR')\n",
        "ax.bar(x_pos + width, max_fpr, width, color='grey', label='Max FPR')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Models', fontsize=12)\n",
        "ax.set_ylabel('False Positive Rate (%)', fontsize=12)\n",
        "ax.set_xticks(x_pos + width / 2)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.legend(loc='upper left')\n",
        "\n",
        "# Set y-axis range\n",
        "ax.set_ylim(0, 10)\n",
        "ax.spines['left'].set_linewidth(2)\n",
        "\n",
        "y_ticks = np.arange(0, 11, 2)  # 0, 2, 4, 6, ...\n",
        "ax.set_yticks(y_ticks)\n",
        "# Add grid and show plot\n",
        "ax.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1m4E2ETJUZqi",
      "metadata": {
        "id": "1m4E2ETJUZqi"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}